Two-sample
==========

-  We can get confidence intervals for the p-value -- this tells us how
   many iterations we need to achieve a certain precision
-  Choice of test statistic is flexible -- choose one that makes sense
   for your data, gives high power

   -  Now, you can specify 'mean' or 't'
   -  Future improvements: user can choose from a more complete library 
      of test statistics

.. ipython:: python

    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd

    import permute
    from permute import core, stratified

    from scipy import stats

Two-sample permutation tests
============================

Motivating example - teaching evaluations
-----------------------------------------

Do students give higher ratings to male teachers?

An online experiment was done with two professors, one male and one
female.

Each professor taught two sections. In one section, they used a male
name. In the other, they used a female name. The students didn't know
the teacher's real gender.

We can test whether student evaluations of teaching are biased by
comparing the ratings when the professor used a male name vs. a female
name.

The data come from MacNell et. al. (2014).

We'll begin by testing whether the ratings of the two instructors were
actually significantly different.

.. ipython:: python

    import permute.data as data
    ratings = pd.DataFrame(data.macnell2014())
    ratings.loc[:,'knowledgeable':'taidgender'].head()


How should we analyze the data?
===============================

We'll use the unpaired test statistic

.. math::  t = \frac{\text{mean(rating for male prof) - mean(rating for female prof)}}{\sqrt{\text{pooled SD of ratings}}}

t-test
------

Null hypothesis: reported/perceived teacher gender has no effect on
teacher ratings

Alternative hypothesis: teacher ratings differ by reported/perceived
teacher gender

Assumptions: - Ratings are normally distributed - They are on a Likert
1-5 scale. Definitely not normal - Noise is zero-mean and constant
variance across raters - How to interpret "noise" in this context? -
Constant variance is not plausible: some raters might give a range of
scores, other raters might always give 5 - Independence between
observations - Students might talk about ratings with their peers in the
class, creating dependence

.. ipython:: python

    maleprof   = ratings.overall[ratings.tagender==1]
    femaleprof = ratings.overall[ratings.tagender==0]
    df = len(maleprof) + len(femaleprof) - 2
    (t, p) = stats.ttest_ind(maleprof, femaleprof)
    print('Test statistic:', np.round(t, 5))
    print('P-value (two-sided):', np.round(p, 5))


Permutation test
----------------

Same statistic, different way to calculate p-value

 Null hypothesis: the ratings are uninfluenced by instructor -- any particular student
 would assign the same rating to either instructor

 Alternative hypothesis: the ratings differ by instructor -- some students would assign 
 different ratings to the two instructors

 Assumptions: - Randomization is fair and independent across units -
This can be verified from the experimental design - That's it!

.. ipython:: python

    p, t = permute.core.two_sample(maleprof, femaleprof, stat='t', alternative='two-sided')
    print('Test statistic:', np.round(t, 5))
    print('P-value (two-sided):', np.round(p, 5))

    print('\n\nRuns faster, but there is more uncertainty around the p-value\n')
    p, t = permute.core.two_sample(maleprof, femaleprof, reps=100, stat='t', alternative='two-sided')

    print('Test statistic:', np.round(t, 5))
    print('P-value (two-sided):', np.round(p, 5))


.. ipython:: python

	p, t, distr = permute.core.two_sample(maleprof, femaleprof, stat='t', reps = 10000, 
                                      alternative='greater', keep_dist=True, seed=55)
	n, bins, patches = plt.hist(distr, 25, histtype='bar', normed=True)
	plt.title('Permutation Null Distribution')
	plt.axvline(x = -t, color = 'red')
	x = np.linspace(stats.t.ppf(0.0001, df),
              stats.t.ppf(0.9999, df), 100)
	plt.plot(x, stats.t.pdf(x, df), lw=2, alpha=0.6)


The plot above shows the null distribution generated by 10,000 permutations of the data.  
The t distribution is superimposed for comparison.  The null distribution is much flatter
around 0 than the t distribution.  This is the source of the difference in p-values between
the two tests.


Stratified Permutation Tests
============================

Some experimental designs have natural groupings. It makes sense to
estimate effects within groups, then combine within-group estimates.

To turn this idea into a permutation test, we carry out permutations within groups,
then aggregate the test statistics across groups. This helps control for group-level effects.

More on teaching evaluations
----------------------------

We established that one instructor got higher ratings from students, but the difference was
not significant. Now we may ask, did students ratings differ according to the gender that the
instructor claimed to be?

If there is no gender bias in the ratings, then students should give the same rating to the male instructor
regardless of the gender he claims to be and students should give the same rating to the female instructor
regardless of the gender she claims to be.  However, we don't necessarily believe that students would rate 
the two instructors the same, since there may be some difference in their teaching styles.

Null hypothesis: student by student, the instructor would receive the same rating regardless of reported gender

Alternative hypothesis: there is at least one student who would rate their instructor higher if they identified
as male

The test statistic we use within groups is the Spearman correlation. For each instructor, we compute the
correlation between their rating and reported gender, then add the absolute values of the correlations for
the instructors.

.. ipython:: python

	(rho, plower, pupper, pboth, sim) = permute.stratified.sim_corr(x = ratings.overall, y = ratings.taidgender, \
                                                                reps = 10000, group = ratings.tagender, \
																seed = 56)
	print 'Test statistic:', np.round(rho, 5)
	print 'One-sided (upper) p-value:', np.round(pupper, 5)

	n, bins, patches = plt.hist(sim, 20, histtype='bar')
	plt.title('Permutation Null Distribution')
	plt.axvline(x = rho, color = 'red')

At the 10% level, there is a significant difference in ratings between male-identified and female-identified
instructors.  We could not have computed this p-value with any common distribution, since the null hypothesis
assumes some observations (ratings for a single instructor) are exchangeable but others are not.


References
----------

Boring, A., Ottoboni, K., and Stark, P.B. (in preparation), "Student
Evaluations of Teaching (Mostly) Do Not Measure Teaching Effectiveness."

MacNell, L., Driscoll, A., and Hunt, A.N. (2014), "Whatâ€™s in a Name:
Exposing Gender Bias in Student Ratings of Teaching," Innovative Higher
Education, 1-13.

----

.. automodule:: permute
