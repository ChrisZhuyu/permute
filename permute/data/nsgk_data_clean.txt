---------------------------------------------------------
$ grep -n --context=1 '13,87,2,1' nsgk.csv
530-13,32,2,1
531:13,87,2,1
532:13,87,2,1
533-13,95,2,1

# remove duplicate line
$ sed -i -e '532d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '22,36,6,1' nsgk.csv
1460-21,106,6,1
1461:22,36,6,1
1462:22,36,6,1
1463-22,78,6,1

# remove duplicate line
$ sed -i -e '1462d' nsgk.csv

---------------------------------------------------------
## This is the beginning of a suspicious block of data
# 28,78,7,1
# 28,79,7,1
# 28,80,7,1
# 28,90,7,1
# 28,106,7,1
# 28,121,7,1
# 29,45,7,1
# 29,46,7,1
# 29,50,7,1
# 29,78,7,1
# 28,79,7,1
# 28,80,7,1
# 28,90,7,1
# 28,106,7,1
# 28,121,7,1
# 30,45,7,1
# 30,46,7,1
# 30,50,7,1
# 30,78,7,1
# 30,79,7,1
# 30,80,7,1
# 30,90,7,1
# 30,121,7,1
## It looks like the block starting with 28 was cut-and-pasted
## for 29 and 30.  But only the first occurrence of 28 was
## replaced with 29 and all occurences of 28 were replaced with
## 30.  I am going to just update all the 28s to 29s below.

$ grep -n --context=1 '28,79,7,1' nsgk.csv
1628-28,78,7,1
1629:28,79,7,1
1630-28,80,7,1
--
1637-29,78,7,1
1638:28,79,7,1
1639-28,80,7,1

# fix typo
$ sed -i '1638s/28,79,7,1/29,79,7,1/' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '28,80,7,1' nsgk.csv
1629-28,79,7,1
1630:28,80,7,1
1631-28,90,7,1
--
1638-29,79,7,1
1639:28,80,7,1
1640-28,90,7,1

# fix typo
$ sed -i '1639s/28,80,7,1/29,80,7,1/' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '28,90,7,1' nsgk.csv
1630-28,80,7,1
1631:28,90,7,1
1632-28,106,7,1
--
1639-29,80,7,1
1640:28,90,7,1
1641-28,106,7,1

# fix typo
$ sed -i '1640s/28,90,7,1/29,90,7,1/' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '28,106,7,1' nsgk.csv
1631-28,90,7,1
1632:28,106,7,1
1633-28,121,7,1
--
1640-29,90,7,1
1641:28,106,7,1
1642-28,121,7,1

# fix typo
$ sed -i '1641s/28,106,7,1/29,106,7,1/' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '28,121,7,1' nsgk.csv
1632-28,106,7,1
1633:28,121,7,1
1634-29,45,7,1
--
1641-29,106,7,1
1642:28,121,7,1
1643-30,45,7,1

# fix typo
$ sed -i '1642s/28,121,7,1/29,121,7,1/' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '30,46,8,1' nsgk.csv
1886-30,45,8,1
1887:30,46,8,1
1888:30,46,8,1
1889-30,78,8,1

# remove duplicate line
$ sed -i -e '1888d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '20,45,2,3' nsgk.csv
3549-19,137,2,3
3550:20,45,2,3
3551-20,46,2,3
--
3553-20,21,2,3
3554:20,45,2,3
3555-20,136,2,3

## Weird
# 20,45,2,3
# 20,46,2,3
# 20,94,2,3
# 20,21,2,3
# 20,45,2,3
# 20,136,2,3
# 20,137,2,3
# 20,150,2,3
#
## I expected the second column above to be strictly increasing
## so I am suspicious of 20,21,2,3 and 20,45,2,3
## Since 20,45,2,3 is a duplicate, I will definitely remove it
## But I will need to check with Naomi about 20,21,2,3

# remove duplicate line
$ sed -i -e '3554d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '3,113,5,4' nsgk.csv
4786-3,36,5,4
4787:3,113,5,4
4788:3,113,5,4
4789-4,113,5,4

# remove duplicate line
$ sed -i -e '4788d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '4,113,5,4' nsgk.csv
4787-3,113,5,4
4788:4,113,5,4
4789:4,113,5,4
4790-5,113,5,4

# remove duplicate line
$ sed -i -e '4789d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '5,113,5,4' nsgk.csv
4788-4,113,5,4
4789:5,113,5,4
4790:5,113,5,4
4791-7,105,5,4

# remove duplicate line
$ sed -i -e '4790d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '7,113,5,4' nsgk.csv
4790-7,105,5,4
4791:7,113,5,4
4792:7,113,5,4
4793-8,36,5,4

# remove duplicate line
$ sed -i -e '4792d' nsgk.csv

---------------------------------------------------------
$ grep -n --context=1 '8,113,5,4' nsgk.csv
4792-8,36,5,4
4793:8,113,5,4
4794:8,113,5,4
4795-9,36,5,4

# remove duplicate line
$ sed -i -e '4794d' nsgk.csv

---------------------------------------------------------
---------------------------------------------------------
---------------------------------------------------------
$ grep -n --context 1 '26,79,1,5' nsgk.csv
5527-26,24,1,5
5528:26,79,1,5
5529-26,32,1,5
--
5534-26,80,1,5
5535:26,79,1,5
5536-26,82,1,5

## This is odd

# remove duplicate line
$ sed -i -e '5535d' nsgk.csv

---------------------------------------------------------
## I got tired of going through things one by one
## so I decided to remove duplicate consecutive lines

$ sed -i -e '6468d' nsgk.csv
$ sed -i -e '6924d' nsgk.csv
$ sed -i -e '7671d' nsgk.csv
$ sed -i -e '8879d' nsgk.csv
$ sed -i -e '9651d' nsgk.csv
$ sed -i -e '11435d' nsgk.csv
$ sed -i -e '15252d' nsgk.csv
$ sed -i -e '17894d' nsgk.csv
$ sed -i -e '19972d' nsgk.csv
$ sed -i -e '20730d' nsgk.csv
$ sed -i -e '20878d' nsgk.csv
$ sed -i -e '21028d' nsgk.csv
$ sed -i -e '21968d' nsgk.csv
$ sed -i -e '22048d' nsgk.csv
$ sed -i -e '22855d' nsgk.csv
$ sed -i -e '22865d' nsgk.csv
$ sed -i -e '23307d' nsgk.csv
$ sed -i -e '23418d' nsgk.csv

---------------------------------------------------------
$ grep -n --context 1 '32,24,7,5' nsgk.csv
8288-32,15,7,5
8289:32,24,7,5
8290-32,32,7,5
8291:32,24,7,5
8292-32,29,7,5

# remove duplicate line
$ sed -i -e '8291d' nsgk.csv

---------------------------------------------------------
$  grep -n --context 1 '23,24,8,5' nsgk.csv
8785-23,21,8,5
8786:23,24,8,5
8787-23,25,8,5
--
8789-23,32,8,5
8790:23,24,8,5
8791-23,45,8,5

# remove duplicate line
$ sed -i -e '8790d' nsgk.csv

---------------------------------------------------------
$ grep -n --context 1 '16,126,1,8' nsgk.csv
12018-16,121,1,8
12019:16,126,1,8
12020-16,137,1,8
--
12153-16,120,1,8
12154:16,126,1,8
12155-26,141,1,8

# remove duplicate line
$ sed -i -e '12154d' nsgk.csv

---------------------------------------------------------
