{
 "metadata": {
  "name": "",
  "signature": "sha256:27f57cf95c45ad7d7b0ba25d50411feb227c061500654be4b9103b95ca204f2a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_Last modified 26 December 2014 by PBS_\n",
      "\n",
      "###This notebook implements a variety of permutation tests, including stratified permutation tests.\n",
      "###It also implements exact confidence intervals for binomial p and hypergeometric parameters, by inverting tests.\n",
      "\n",
      "<hr />"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import math\n",
      "import numpy as np\n",
      "import scipy\n",
      "from scipy.stats import binom, hypergeom\n",
      "from scipy.optimize import brentq\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binoLowerCL(n, x, cl = 0.975, p = None, xtol=1e-12, rtol=4.4408920985006262e-16, maxiter=100):\n",
      "    \"Lower confidence level cl confidence interval for Binomial p, for x successes in n trials\"\n",
      "    if p is None:\n",
      "            p = float(x)/float(n)\n",
      "    lo = 0.0\n",
      "    if (x > 0):\n",
      "            f = lambda q: cl - scipy.stats.binom.cdf(x-1, n, q)\n",
      "            lo = brentq(f, 0.0, p, xtol, rtol, maxiter)\n",
      "    return lo\n",
      "\n",
      "def binoUpperCL(n, x, cl = 0.975, p = None,  xtol=1e-12, rtol=4.4408920985006262e-16, maxiter=100):\n",
      "    \"Upper confidence level cl confidence interval for Binomial p, for x successes in n trials\"\n",
      "    if p is None:\n",
      "            p = float(x)/float(n)\n",
      "    hi = 1.0\n",
      "    if (x < n):\n",
      "            f = lambda q: scipy.stats.binom.cdf(x, n, q) - (1-cl)\n",
      "            hi = brentq(f, p, 1.0, xtol, rtol, maxiter)\n",
      "    return hi\n",
      "\n",
      "def permuTestMean(x, y, reps = 10**5, stat = 'mean', side = 'greater_than', CI =  False, CL = 0.95):\n",
      "    \"\"\"\n",
      "       One-sided or two-sided, two-sample permutation test for equality of two \n",
      "       means, with p-value estimated by simulated random sampling with reps replications.\n",
      "       \n",
      "       Tests the hypothesis that x and y are a random partition of x,y\n",
      "       against the alternative that x comes from a population with mean\n",
      "           (a) greater than that of the population from which y comes, if side = 'greater_than'\n",
      "           (b) less than that of the population from which y comes, if side = 'less_than'\n",
      "           (c) different from that of the population from which y comes, if side = 'both'\n",
      "       \n",
      "       If stat == 'mean', the test statistic is (mean(x) - mean(y))\n",
      "       (equivalently, sum(x), since those are monotonically related)\n",
      "       \n",
      "       If stat == 't', the test statistic is the two-sample t-statistic--but the p-value \n",
      "       is still estimated by the randomization, approximating the permutation distribution.\n",
      "       The t-statistic is computed using scipy.stats.ttest_ind\n",
      "       \n",
      "       If CI == 'upper', computes an upper confidence bound on the true\n",
      "       p-value based on the simulations by inverting Binomial tests.\n",
      "       \n",
      "       If CI == 'lower', computes a lower confidence bound on the true\n",
      "       p-value based on the simulations by inverting Binomial tests.\n",
      "       \n",
      "       If CI == 'both', computes lower and upper confidence bounds on the true\n",
      "       p-value based on the simulations by inverting Binomial tests.\n",
      "       \n",
      "       CL is the confidence limit for the confidence bounds.\n",
      "       \n",
      "       output is the estimated p-value and the test statistic, if CI == False\n",
      "       output is <estimated p-value, confidence bound on p-value, test statistic> if CI in {'lower','upper'}\n",
      "       output is <estimated p-value, [lower confidence bound, upper confidence bound], test statistic> if CI == 'both'\n",
      "       \n",
      "       Dependencies: numpy, numpy.random, scipy.stats, binoUpperCL, binoLowerCL\n",
      "       \n",
      "    \"\"\"\n",
      "    z  = np.concatenate([x, y])   # pooled responses\n",
      "    stats = dict( \\\n",
      "             mean = lambda u: np.mean(u[:len(x)])-np.mean(u[len(x):]),\n",
      "             t = lambda u: scipy.stats.ttest_ind(u[:len(y)], u[len(y):], equal_var=True)[0] \\\n",
      "            )\n",
      "    try:\n",
      "        tst = stats[stat]\n",
      "    except KeyError:\n",
      "        raise ValueError(\"Unrecognized test statistic (stat): \" + stat)    \n",
      "    if side == 'greater_than':\n",
      "        theStat = tst\n",
      "    elif side == 'less_than':\n",
      "        theStat = lambda u: -tst(u)\n",
      "    elif side == 'both':\n",
      "        theStat = lambda u: math.fabs(tst(u))\n",
      "    else:\n",
      "        raise ValueError(\"Unrecognized side choice: \" + side)\n",
      "    ts = theStat(z)\n",
      "    hits = np.sum([ (theStat(np.random.permutation(z)) >= ts) for i in range(reps)])\n",
      "    if CI == 'upper':\n",
      "        return float(hits)/float(reps), binoUpperCL(reps, hits, cl = CL), ts\n",
      "    elif CI == 'lower':\n",
      "        return float(hits)/float(reps), binoLowerCL(reps, hits, cl = CL), ts\n",
      "    elif CI == 'both':\n",
      "        return float(hits)/float(reps),  \\\n",
      "                 (binoLowerCL(reps, hits, cl = 1-(1-CL)/2), binoUpperCL(reps, hits, cl = 1-(1-CL)/2)), \\\n",
      "                 ts\n",
      "    else:\n",
      "        return float(hits)/float(reps), ts\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stratifiedPermutationTestMean(group, condition, response, groups, conditions):\n",
      "    '''\n",
      "    Calculates variability in sample means between treatment conditions, within groups.\n",
      "    If there are two treatment conditions, the test statistic is the difference in means,\n",
      "    aggregated across groups.\n",
      "    If there are more than two treatment conditions, the test statistic is the standard deviation of\n",
      "    the means, aggregated across groups. \n",
      "    '''\n",
      "    tst = 0.0\n",
      "    if (len(groups) < 2):\n",
      "        raise ValueError('Number of groups must be at least 2.')\n",
      "    elif (len(groups) == 2):\n",
      "        stat = lambda u: u[0] - u[1]\n",
      "    elif (len(groups) > 2):\n",
      "        stat = lambda u: np.std(u)\n",
      "    for g in groups:\n",
      "        gg = group == g\n",
      "        x = [gg & (condition == c) for c in conditions]\n",
      "        tst += stat([response[x[j]].mean() for j in range(len(x))])\n",
      "    return tst\n",
      "\n",
      "\n",
      "def permuteWithinGroups(group, condition, groups):\n",
      "    permuted = condition\n",
      "    for g in groups:\n",
      "        gg = group == g\n",
      "        permuted[gg] = np.random.permutation(condition[gg])      \n",
      "    return permuted\n",
      "\n",
      "\n",
      "def stratifiedPermutationTest(group, condition, response, iterations=1.0e4, testStatistic=stratifiedPermutationTestMean):\n",
      "    '''\n",
      "    Stratified permutation test using the sum of the differences in means between two or more conditions in\n",
      "    each group (stratum) as the test statistic.\n",
      "    The test statistic is\n",
      "        \\sum_{g in groups} [\n",
      "                            f(mean(response for cases in group g assigned to each condition))\n",
      "                           ].\n",
      "    The function f is the difference if there are two conditions, and the standard deviation if there are\n",
      "    more than two conditions.\n",
      "    There should be at least one group and at least two conditions.\n",
      "    Under the null hypothesis, all assignments to the two conditions that preserve the number of\n",
      "    cases assigned to the conditions are equally likely.\n",
      "    Groups in which all cases are assigned to the same condition are skipped; they do not contribute \n",
      "    to the p-value since all randomizations give the same contribution to the difference in means.\n",
      "    \n",
      "    Dependencies: numpy (as np)\n",
      "    '''   \n",
      "    groups = np.unique(group)\n",
      "    conditions = np.unique(condition) \n",
      "    if len(conditions) < 2:\n",
      "        return 1.0, 1.0, 1.0, np.nan, None\n",
      "    else:\n",
      "        tst = testStatistic(group, condition, response, groups, conditions)\n",
      "        dist = np.zeros(iterations)\n",
      "        for i in range(np.as_int(iterations)):\n",
      "             dist[i] = testStatistic( group, \n",
      "                                      permuteWithinGroups(group, condition, groups),\n",
      "                                      response, groups, conditions\n",
      "                                    )\n",
      "            \n",
      "    # define the conditions, then map count_nonzero over them\n",
      "        conds = [dist <= tst, dist >= tst, abs(dist) >= abs(tst)]\n",
      "        pLeft, pRight, pBoth = np.array(map(np.count_nonzero, conds))/float(iterations)\n",
      "        return pLeft, pRight, pBoth, tst, dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "group =     np.array([1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3])\n",
      "condition = np.array([1,1,1,2,2,2,3,3,3,1,1,1,2,2,2,3,3,3,1,1,1,2,2,2,3,3,3])\n",
      "response =  np.array([1,1,0,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stratifiedPermutationTest(group, condition, response, iterations=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "(0.94899999999999995,\n",
        " 0.32200000000000001,\n",
        " 0.32200000000000001,\n",
        " 0.81649658092772603,\n",
        " array([ 0.54433105,  0.54433105,  0.27216553,  1.01573557,  0.27216553,\n",
        "         0.81649658,  0.27216553,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.54433105,  0.27216553,  0.81649658,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.27216553,  0.27216553,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.27216553,  0.54433105,  1.01573557,  0.81649658,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.27216553,  0.27216553,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.54433105,  1.01573557,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.27216553,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.74357005,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  0.27216553,\n",
        "         0.81649658,  0.81649658,  0.27216553,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.74357005,  0.54433105,\n",
        "         0.81649658,  0.27216553,  0.27216553,  0.54433105,  0.81649658,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  0.47140452,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.81649658,  0.74357005,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.        ,  0.81649658,  0.81649658,  0.27216553,  0.27216553,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.27216553,  0.81649658,  0.74357005,  0.27216553,  0.81649658,\n",
        "         0.81649658,  0.81649658,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  1.01573557,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.81649658,  1.01573557,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.54433105,  0.54433105,  0.27216553,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.81649658,  0.54433105,  0.47140452,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.27216553,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.        ,  0.74357005,  0.81649658,  0.54433105,  0.        ,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.81649658,  0.81649658,  0.74357005,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.54433105,  0.54433105,  1.01573557,  0.54433105,  0.81649658,\n",
        "         0.81649658,  0.74357005,  0.81649658,  0.81649658,  0.27216553,\n",
        "         1.01573557,  0.81649658,  1.01573557,  0.        ,  1.21497457,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.        ,  0.81649658,  0.27216553,  0.54433105,\n",
        "         1.01573557,  1.01573557,  0.27216553,  0.27216553,  0.        ,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.        ,  0.81649658,\n",
        "         0.74357005,  0.54433105,  0.54433105,  0.54433105,  0.27216553,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.81649658,  0.54433105,\n",
        "         0.81649658,  0.27216553,  0.74357005,  1.01573557,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.54433105,  1.01573557,  0.81649658,  0.54433105,\n",
        "         0.54433105,  0.        ,  0.27216553,  0.27216553,  0.81649658,\n",
        "         1.01573557,  0.81649658,  0.54433105,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.        ,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.81649658,  0.54433105,  0.74357005,\n",
        "         0.54433105,  1.01573557,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.47140452,  0.74357005,  0.81649658,  0.27216553,\n",
        "         0.74357005,  0.54433105,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.81649658,  0.27216553,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.27216553,  0.27216553,\n",
        "         0.81649658,  0.54433105,  0.81649658,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.81649658,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.47140452,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.        ,  0.27216553,  0.54433105,  0.27216553,\n",
        "         0.54433105,  0.        ,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  1.01573557,  1.01573557,  0.81649658,  1.01573557,\n",
        "         0.27216553,  0.27216553,  0.81649658,  0.81649658,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.        ,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.81649658,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.74357005,  0.27216553,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.74357005,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.27216553,  0.81649658,  0.81649658,\n",
        "         1.01573557,  0.54433105,  0.27216553,  0.27216553,  0.81649658,\n",
        "         0.27216553,  0.74357005,  0.54433105,  0.        ,  0.27216553,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.27216553,  0.81649658,\n",
        "         1.01573557,  0.27216553,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.54433105,  0.27216553,\n",
        "         1.01573557,  0.54433105,  0.54433105,  0.54433105,  0.27216553,\n",
        "         0.54433105,  0.74357005,  0.81649658,  0.81649658,  0.81649658,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.27216553,  0.81649658,\n",
        "         0.74357005,  0.81649658,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.74357005,  0.81649658,  0.27216553,  0.74357005,  0.54433105,\n",
        "         0.27216553,  0.54433105,  0.27216553,  0.74357005,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.27216553,  0.81649658,\n",
        "         0.81649658,  0.27216553,  0.27216553,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.27216553,  0.27216553,  0.81649658,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.        ,  0.54433105,\n",
        "         0.54433105,  0.27216553,  1.01573557,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.        ,  0.27216553,  0.27216553,\n",
        "         0.81649658,  0.81649658,  0.81649658,  0.27216553,  0.54433105,\n",
        "         0.        ,  0.81649658,  0.54433105,  0.        ,  1.01573557,\n",
        "         1.01573557,  0.54433105,  0.81649658,  0.74357005,  0.        ,\n",
        "         0.74357005,  0.54433105,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.81649658,  0.54433105,\n",
        "         0.        ,  0.81649658,  0.54433105,  0.54433105,  1.01573557,\n",
        "         0.27216553,  0.54433105,  0.74357005,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.27216553,  0.27216553,  0.81649658,\n",
        "         0.74357005,  1.01573557,  0.74357005,  0.        ,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.27216553,  0.27216553,\n",
        "         0.81649658,  0.27216553,  0.        ,  0.74357005,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.74357005,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.27216553,  0.27216553,\n",
        "         0.81649658,  0.81649658,  0.81649658,  0.        ,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.27216553,  1.01573557,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  1.01573557,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.27216553,  0.81649658,  1.01573557,  0.54433105,\n",
        "         0.74357005,  0.27216553,  0.27216553,  0.74357005,  0.27216553,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.27216553,  0.27216553,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.27216553,  0.54433105,  0.74357005,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.81649658,  0.81649658,  0.        ,\n",
        "         0.54433105,  0.81649658,  1.01573557,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.81649658,  1.01573557,  1.01573557,\n",
        "         0.74357005,  0.54433105,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.74357005,  0.27216553,  0.54433105,\n",
        "         0.54433105,  0.54433105,  0.27216553,  0.81649658,  0.81649658,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.74357005,  0.27216553,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.54433105,  0.81649658,\n",
        "         0.74357005,  0.81649658,  0.81649658,  0.27216553,  0.81649658,\n",
        "         1.01573557,  1.01573557,  0.27216553,  0.81649658,  0.27216553,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.81649658,  0.27216553,  1.01573557,\n",
        "         0.27216553,  0.27216553,  0.81649658,  0.81649658,  0.54433105,\n",
        "         0.81649658,  0.27216553,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.81649658,  0.27216553,  0.27216553,\n",
        "         0.27216553,  0.47140452,  0.81649658,  0.81649658,  0.81649658,\n",
        "         1.01573557,  0.54433105,  0.81649658,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.27216553,  0.27216553,  0.54433105,  0.        ,\n",
        "         0.81649658,  0.27216553,  0.27216553,  0.27216553,  0.54433105,\n",
        "         0.        ,  0.54433105,  0.54433105,  0.27216553,  1.01573557,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.81649658,  0.        ,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.54433105,  0.81649658,\n",
        "         0.27216553,  0.27216553,  0.27216553,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.81649658,  0.        ,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.81649658,  1.01573557,\n",
        "         1.01573557,  0.54433105,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.54433105,  1.01573557,  0.54433105,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.81649658,  0.81649658,\n",
        "         0.54433105,  1.01573557,  0.81649658,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.81649658,  0.81649658,  0.74357005,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.27216553,  0.74357005,\n",
        "         0.81649658,  0.27216553,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.54433105,  0.27216553,\n",
        "         0.        ,  0.74357005,  0.54433105,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.54433105,  0.27216553,\n",
        "         1.01573557,  0.74357005,  0.        ,  0.54433105,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.54433105,  0.54433105,  0.81649658,\n",
        "         1.21497457,  0.54433105,  0.54433105,  0.27216553,  0.        ,\n",
        "         0.27216553,  0.27216553,  0.        ,  0.81649658,  0.27216553,\n",
        "         0.27216553,  0.        ,  0.27216553,  0.81649658,  0.54433105,\n",
        "         0.54433105,  0.81649658,  1.01573557,  0.81649658,  1.21497457,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.27216553,  0.81649658,\n",
        "         0.74357005,  0.81649658,  1.01573557,  0.27216553,  0.81649658,\n",
        "         0.54433105,  0.81649658,  0.81649658,  0.54433105,  0.27216553,\n",
        "         0.81649658,  0.74357005,  0.81649658,  0.54433105,  0.27216553,\n",
        "         0.74357005,  0.47140452,  0.74357005,  0.54433105,  0.81649658,\n",
        "         0.27216553,  0.81649658,  0.54433105,  0.81649658,  0.81649658,\n",
        "         0.54433105,  0.27216553,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.74357005,  0.54433105,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.81649658,  0.47140452,\n",
        "         0.54433105,  0.81649658,  0.27216553,  0.81649658,  0.54433105,\n",
        "         0.81649658,  0.        ,  0.        ,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.27216553,  0.54433105,  0.54433105,  0.81649658,\n",
        "         0.74357005,  0.54433105,  0.27216553,  0.54433105,  0.54433105,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.81649658,  0.54433105,\n",
        "         0.27216553,  0.        ,  0.74357005,  0.54433105,  0.54433105,\n",
        "         1.01573557,  0.81649658,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.27216553,  0.81649658,  0.81649658,  0.47140452,  0.54433105,\n",
        "         0.81649658,  0.81649658,  0.81649658,  0.54433105,  0.81649658,\n",
        "         0.27216553,  0.54433105,  0.27216553,  0.81649658,  0.27216553,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.54433105,  0.54433105,\n",
        "         0.54433105,  0.81649658,  0.54433105,  0.        ,  0.74357005,\n",
        "         0.27216553,  0.54433105,  0.81649658,  0.47140452,  0.27216553,\n",
        "         0.54433105,  0.54433105,  0.54433105,  1.01573557,  0.27216553,\n",
        "         0.54433105,  0.81649658,  0.81649658,  0.81649658,  0.27216553,\n",
        "         0.54433105,  0.81649658,  1.01573557,  0.81649658,  0.81649658,\n",
        "         0.81649658,  0.54433105,  0.27216553,  0.27216553,  1.01573557,\n",
        "         0.54433105,  0.54433105,  0.54433105,  0.81649658,  0.54433105,\n",
        "         0.81649658,  0.54433105,  0.81649658,  1.01573557,  0.81649658,\n",
        "         0.81649658,  0.54433105,  0.54433105,  0.27216553,  0.54433105,\n",
        "         0.81649658,  0.27216553,  0.27216553,  0.27216553,  0.81649658]))"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lec = pd.read_csv('./Lecturer/lecturer.csv')\n",
      "lec['gpaDiff'] = lec['BGPA'] - lec['AGPA']\n",
      "lec.columns\n",
      "group = lec['secb']\n",
      "condition = lec['seca']\n",
      "response = lec['BGPA']\n",
      "[pleft, pright, pboth, tst, dist] = stratifiedPermutationTest(group, condition, response, iterations=10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pleft"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "0.86639999999999995"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pright"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "0.1336"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}